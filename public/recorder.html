<Component id="audio_holder"></Component>

<script>
    function recorder() {

        var $scope = this;
        $scope.stream = null;
        $scope.recording = false;
        $scope.encoder = null;
        $scope.ws = null;
        $scope.input = null;
        $scope.node = null;
        $scope.samplerate = 22050;
        $scope.samplerates = [ 8000, 11025, 12000, 16000, 22050, 24000, 32000, 44100, 48000 ];
        $scope.bitrate = 64;
        $scope.bitrates = [ 8, 16, 24, 32, 40, 48, 56, 64, 80, 96, 112, 128, 144, 160, 192, 224, 256, 320 ];
        $scope.recordButtonStyle = "red-btn";

        $scope.startRecording = function(e) {
            if ($scope.recording)
                return;
            console.log('start recording');
            $scope.encoder = new Worker('/js/workers/encoder.js');
            console.log('initializing encoder with samplerate = ' + $scope.samplerate + ' and bitrate = ' + $scope.bitrate);
            $scope.encoder.postMessage({ cmd: 'init', config: { samplerate: $scope.samplerate, bitrate: $scope.bitrate } });

            $scope.encoder.onmessage = function(e) {
                
                if (e.data.cmd == 'end') {
                    //$scope.forceDownload(e.data.buf);
                    $scope.blob = e.data.buf;
                    $scope.encoder.terminate();
                    $scope.encoder = null;
                }
            };
            console.log( navigator.mediaDevices.getSupportedConstraints() );
            if(navigator.webkitGetUserMedia)
                navigator.webkitGetUserMedia({ video: false, audio: true, channelCount : 2 }, $scope.gotUserMedia, $scope.userMediaFailed);
            else if(navigator.mozGetUserMedia)
                navigator.mozGetUserMedia({ video: false, audio: true, channelCount : 2 }, $scope.gotUserMedia, $scope.userMediaFailed);
            else
                navigator.getUserMedia({ video: false, audio: true, channelCount : 2 }, $scope.gotUserMedia, $scope.userMediaFailed);
                
        };

        $scope.userMediaFailed = function(code) {
            console.log('grabbing microphone failed: ' + code);
        };

        $scope.gotUserMedia = function(localMediaStream) {
            $scope.recording = true;
            $scope.recordButtonStyle = '';

            console.log('success grabbing microphone');
            $scope.stream = localMediaStream;

            var audio_context;
            if(typeof webkitAudioContext !== 'undefined'){
                audio_context = new webkitAudioContext;
            }else if(typeof AudioContext !== 'undefined'){
                audio_context = new AudioContext;
            }
            else {
                console.error('JavaScript execution environment (Browser) does not support AudioContext interface.');
            }

            $scope.input = audio_context.createMediaStreamSource($scope.stream);
            /*
                base pattern BEGIN
            */

            if($scope.input.context.createJavaScriptNode)
                $scope.node = $scope.input.context.createJavaScriptNode(4096, 1, 1);
            else if($scope.input.context.createScriptProcessor)
                $scope.node = $scope.input.context.createScriptProcessor(4096, 1, 1);
            else
                console.error('Could not create audio node for JavaScript based Audio Processing.');

            console.log('sampleRate: ' + $scope.input.context.sampleRate);

            $scope.node.onaudioprocess = function(e) {
                if (!$scope.recording)
                    return;
                console.log(e);
                var channelLeft = e.inputBuffer.getChannelData(0);
                $scope.encoder.postMessage({ cmd: 'encode', buf: null, L : $scope.leftSpeaker, R : $scope.rightSpeaker });
            };
            /*
                base pattern END
            */
            if($scope.input.context.createJavaScriptNode)
                $scope.LeftProcessor = $scope.input.context.createJavaScriptNode(4096, 1, 1);
            else if($scope.input.context.createScriptProcessor)
                $scope.LeftProcessor = $scope.input.context.createScriptProcessor(4096, 1, 1);
            else
                console.error('Could not create audio node for JavaScript based Audio Processing.');

            var state = 0;

            $scope.LeftProcessor.onaudioprocess = function(e) {
                if (!$scope.recording) return;
                //console.log(e);
                $scope.leftSpeaker = e.inputBuffer.getChannelData(0);;
                state += 1;
                if(state == 2) {
                    $scope.encoder.postMessage({ cmd: 'encode', buf: null, L : $scope.leftSpeaker, R : $scope.rightSpeaker });
                    state = 0;
                }
            };
            /*
                base pattern END
            */
            if($scope.input.context.createJavaScriptNode)
                $scope.RightProcessor = $scope.input.context.createJavaScriptNode(4096, 1, 1);
            else if($scope.input.context.createScriptProcessor)
                $scope.RightProcessor = $scope.input.context.createScriptProcessor(4096, 1, 1);
            else
                console.error('Could not create audio node for JavaScript based Audio Processing.');

            $scope.RightProcessor.onaudioprocess = function(e) {
                if (!$scope.recording) return;
                $scope.rightSpeaker = e.inputBuffer.getChannelData(0);
                state += 1;
                if(state == 2) {
                    $scope.encoder.postMessage({ cmd: 'encode', buf: null, L : $scope.leftSpeaker, R : $scope.rightSpeaker });
                    state = 0;
                }
            };

            console.log( $scope.input.numberOfInputs , $scope.input.numberOfOutputs  );

            var gainNode = audio_context.createGain();
            gainNode.gain.value = 1;

            var splitter = audio_context.createChannelSplitter(2);
            

            $scope.input.connect(gainNode);
            //gainNode.connect($scope.node);
            gainNode.connect(splitter);

            splitter.connect($scope.LeftProcessor,0,0);
            splitter.connect($scope.RightProcessor,1,0);


            var merger = audio_context.createChannelMerger(2);
            $scope.LeftProcessor.connect(merger,0,0);
            $scope.RightProcessor.connect(merger,0,1);

            merger.connect(audio_context.destination);


            //$scope.node.connect(audio_context.destination);

            //$scope.$apply();
        };

        $scope.stopRecording = function() {
            if (!$scope.recording) {
                return;
            }
            $scope.recordButtonStyle = "red-btn";
            console.log('stop recording');
            var tracks = $scope.stream.getAudioTracks()
            for(var i = tracks.length - 1; i >= 0; --i){
                tracks[i].stop();
            }
            $scope.recording = false;
            $scope.encoder.postMessage({ cmd: 'finish' });

            $scope.input.disconnect();
            $scope.node.disconnect();
            $scope.input = $scope.node = null;
        };

        //create A-element for data BLOB and trigger download
        $scope.forceDownload = function(blob, filename){
            var url = (window.URL || window.webkitURL).createObjectURL(blob);
            var link = window.document.createElement('a');
            link.href = url;
            link.download = filename || 'output.mp3';
            //NOTE: FireFox requires a MouseEvent (in Chrome a simple Event would do the trick)
            var click = document.createEvent("MouseEvent");
            click.initMouseEvent("click", true, true, window, 0, 0, 0, 0, 0, false, false, false, false, 0, null);
            link.dispatchEvent(click);
        }

        $scope.download = async function() {
            if($scope.blob) {
                var url = (window.URL || window.webkitURL).createObjectURL($scope.blob);
                var link = window.document.createElement('a');
                link.href = url;
                link.download = filename || 'output.mp3';
                //NOTE: FireFox requires a MouseEvent (in Chrome a simple Event would do the trick)
                var click = document.createEvent("MouseEvent");
                click.initMouseEvent("click", true, true, window, 0, 0, 0, 0, 0, false, false, false, false, 0, null);
                link.dispatchEvent(click);

            } else {
                alert("no buffer loaded.");
            }
        }
        $scope.play = async function(holder) {
            if($scope.blob) {
                var url = (window.URL || window.webkitURL).createObjectURL($scope.blob);
                var schema = await holder.$.elementSetPacketAsync(`
                    <audio id="audio">
                            <source src="`+url+`" type="audio/mpeg">
                            Your browser does not support the audio tag.
                    </audio>
                `);
                schema.el.audio.play();
            } else {
                alert("no buffer loaded.");
            }
        }

    }
    this.module.exports = recorder;
</script>